# IntegraÃ§Ã£o com OpenAI

DocumentaÃ§Ã£o da integraÃ§Ã£o com OpenAI para anÃ¡lise de risco de pedidos.

## ğŸ“š DocumentaÃ§Ã£o Oficial

- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/chat)
- [Chat Completions Guide](https://platform.openai.com/docs/guides/text-generation)

## ğŸ”‘ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Configure a chave de API do OpenAI:

```bash
export OPENAI_API_KEY=sua_chave_api_aqui
```

Ou no `application.properties`:

```properties
openai.api.key=sua_chave_api_aqui
```

### ConfiguraÃ§Ãµes DisponÃ­veis

```properties
# Base URL (padrÃ£o: https://api.openai.com/v1)
openai.api.base-url=${OPENAI_BASE_URL:https://api.openai.com/v1}

# Chave de API (obrigatÃ³ria)
openai.api.key=${OPENAI_API_KEY:}

# Modelo a ser utilizado (padrÃ£o: gpt-3.5-turbo)
openai.api.model=${OPENAI_MODEL:gpt-3.5-turbo}

# Temperatura (0.0 = determinÃ­stico, padrÃ£o: 0.0)
openai.api.temperature=${OPENAI_TEMPERATURE:0.0}

# MÃ¡ximo de tokens na resposta (padrÃ£o: 10)
openai.api.max-tokens=${OPENAI_MAX_TOKENS:10}
```

## ğŸ—ï¸ Arquitetura da IntegraÃ§Ã£o

### Componentes

1. **OpenAIRiskAnalysisAdapter**: Implementa `RiskAnalysisPort`
2. **OpenAIConfig**: Configura `WebClient` para chamadas HTTP
3. **DTOs**: `OpenAIRequest`, `OpenAIResponse`

### Fluxo

```
Use Case (AnalyzeRiskUseCase)
    â†“
RiskAnalysisPort (interface)
    â†“
OpenAIRiskAnalysisAdapter (implementaÃ§Ã£o)
    â†“
WebClient â†’ OpenAI API (Chat Completions)
    â†“
RiskAnalysisResult (domÃ­nio)
```

## ğŸ”’ ResiliÃªncia

A integraÃ§Ã£o utiliza Resilience4j:

- **Circuit Breaker**: Protege contra falhas em cascata
- **Retry**: Tenta novamente em falhas transitÃ³rias
- **Fallback**: Retorna `PENDING` quando OpenAI indisponÃ­vel

## ğŸ“ Endpoint Utilizado

### Chat Completions

- **Endpoint**: `POST /v1/chat/completions`
- **AutenticaÃ§Ã£o**: Bearer token
- **Request**: `OpenAIRequest` (com prompt estruturado)
- **Response**: `OpenAIResponse` (contÃ©m "LOW" ou "HIGH")

## ğŸ¯ EstratÃ©gia de Prompt

O prompt Ã© estruturado para garantir que a IA retorne apenas "LOW" ou "HIGH":

1. **InstruÃ§Ãµes claras**: Define o papel da IA como sistema de anÃ¡lise de risco
2. **Formato especÃ­fico**: Solicita resposta apenas "LOW" ou "HIGH"
3. **Contexto completo**: Inclui todos os dados relevantes do pedido
4. **CritÃ©rios explÃ­citos**: Define quando retornar LOW vs HIGH

## ğŸ§ª Testes

Execute os testes unitÃ¡rios:

```bash
mvn test -Dtest=OpenAIRiskAnalysisAdapterTest
```

## âš ï¸ Notas Importantes

1. **Custos**: Cada anÃ¡lise consome tokens. Use `gpt-3.5-turbo` para desenvolvimento (mais barato).
2. **Temperatura 0.0**: Garante respostas determinÃ­sticas e consistentes.
3. **Max Tokens 10**: Suficiente para retornar apenas "LOW" ou "HIGH".
4. **Fallback**: Sistema continua funcionando mesmo se OpenAI estiver offline.

## ğŸ’¡ Exemplo de Uso

```java
// No Use Case
RiskAnalysisRequest request = new RiskAnalysisRequest(
    orderId,
    orderAmount,
    customerId,
    customerEmail,
    paymentMethod,
    additionalContext
);

RiskAnalysisResult result = riskAnalysisPort.analyzeRisk(request);
// result.riskLevel() = LOW, HIGH, ou PENDING (se falhou)
```

## ğŸ”„ Fluxo Completo

1. Pedido Ã© pago (status â†’ PAID)
2. `AnalyzeRiskUseCase` Ã© chamado
3. Adapter envia prompt para OpenAI
4. OpenAI retorna "LOW" ou "HIGH"
5. Adapter faz parse e retorna `RiskAnalysisResult`
6. Use Case atualiza `riskLevel` do pedido
7. Pedido Ã© persistido com novo nÃ­vel de risco

