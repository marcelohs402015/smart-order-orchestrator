# Instru√ß√µes: Cria√ß√£o de T√≥picos Kafka

> **üìã Guia para criar os t√≥picos necess√°rios no Kafka antes da integra√ß√£o**

---

## üìå T√≥picos Necess√°rios

Voc√™ precisa criar **4 t√≥picos** no seu Kafka para que a integra√ß√£o funcione corretamente:

### 1. **order-created**
- **Evento:** `OrderCreatedEvent`
- **Publicado quando:** Pedido √© criado com sucesso (Step 1 da Saga)
- **Consumidores t√≠picos:** Notification Service, Inventory Service, Analytics Service

### 2. **payment-processed**
- **Evento:** `PaymentProcessedEvent`
- **Publicado quando:** Pagamento √© processado (Step 2 da Saga)
- **Consumidores t√≠picos:** Inventory Service, Notification Service, Accounting Service

### 3. **saga-completed**
- **Evento:** `SagaCompletedEvent`
- **Publicado quando:** Saga completa com sucesso (todos os 3 steps conclu√≠dos)
- **Consumidores t√≠picos:** Fulfillment Service, Notification Service, Analytics Service

### 4. **saga-failed**
- **Evento:** `SagaFailedEvent`
- **Publicado quando:** Saga falha e compensa√ß√£o √© executada
- **Consumidores t√≠picos:** Notification Service, Inventory Service, Alerting Service

---

## üîß Configura√ß√£o Recomendada dos T√≥picos

### Para Desenvolvimento/Testes:
```bash
# Parti√ß√µes: 3 (permite paralelismo)
# Replica√ß√£o: 1 (desenvolvimento local)
# Retention: 7 dias
# Cleanup Policy: delete
```

### Para Produ√ß√£o:
```bash
# Parti√ß√µes: 6-12 (depende do volume)
# Replica√ß√£o: 3 (alta disponibilidade)
# Retention: 30 dias (ou conforme pol√≠tica)
# Cleanup Policy: delete ou compact (se necess√°rio)
```

---

## üìù Comandos para Criar T√≥picos

### Usando Kafka CLI (kafka-topics.sh):

```bash
# 1. order-created
kafka-topics --create \
  --bootstrap-server <seu-kafka-server>:9092 \
  --topic order-created \
  --partitions 3 \
  --replication-factor 1 \
  --config retention.ms=604800000 \
  --config cleanup.policy=delete

# 2. payment-processed
kafka-topics --create \
  --bootstrap-server <seu-kafka-server>:9092 \
  --topic payment-processed \
  --partitions 3 \
  --replication-factor 1 \
  --config retention.ms=604800000 \
  --config cleanup.policy=delete

# 3. saga-completed
kafka-topics --create \
  --bootstrap-server <seu-kafka-server>:9092 \
  --topic saga-completed \
  --partitions 3 \
  --replication-factor 1 \
  --config retention.ms=604800000 \
  --config cleanup.policy=delete

# 4. saga-failed
kafka-topics --create \
  --bootstrap-server <seu-kafka-server>:9092 \
  --topic saga-failed \
  --partitions 3 \
  --replication-factor 1 \
  --config retention.ms=604800000 \
  --config cleanup.policy=delete
```

### Usando Docker (se Kafka estiver em container):

```bash
# Acessar container do Kafka
docker exec -it <kafka-container-name> bash

# Criar t√≥picos
kafka-topics.sh --create \
  --bootstrap-server localhost:9092 \
  --topic order-created \
  --partitions 3 \
  --replication-factor 1

# Repetir para os outros 3 t√≥picos
```

### Usando Confluent Control Center (UI):

1. Acesse o Confluent Control Center
2. V√° em **Topics** > **Add a Topic**
3. Crie cada t√≥pico com as configura√ß√µes acima

### Usando Kafka Manager / Kafka UI:

1. Acesse a interface web
2. V√° em **Topics** > **Create Topic**
3. Configure cada t√≥pico conforme especificado

---

## ‚úÖ Verificar T√≥picos Criados

### Listar todos os t√≥picos:
```bash
kafka-topics --list --bootstrap-server <seu-kafka-server>:9092
```

### Ver detalhes de um t√≥pico espec√≠fico:
```bash
kafka-topics --describe \
  --bootstrap-server <seu-kafka-server>:9092 \
  --topic order-created
```

### Verificar se t√≥picos existem:
```bash
# Deve retornar os 4 t√≥picos:
# order-created
# payment-processed
# saga-completed
# saga-failed
kafka-topics --list --bootstrap-server <seu-kafka-server>:9092 | grep -E "(order-created|payment-processed|saga-completed|saga-failed)"
```

---

## üîÑ Alternativa: Cria√ß√£o Autom√°tica

**Nota:** Se preferir, a aplica√ß√£o pode criar os t√≥picos automaticamente usando `KafkaAdmin` (opcional no plano). Neste caso, voc√™ **n√£o precisa criar manualmente**, mas √© recomendado criar explicitamente para ter controle sobre as configura√ß√µes.

---

## üìä Estrutura de Dados dos Eventos

Todos os eventos ser√£o serializados como **JSON** e incluir√£o os seguintes campos comuns:

```json
{
  "eventId": "uuid",
  "aggregateId": "uuid (Order ID)",
  "occurredAt": "2024-12-12T10:30:00",
  "eventType": "OrderCreated",
  "eventVersion": "1.0"
}
```

### Headers Kafka (Metadados):
- `eventId`: ID √∫nico do evento
- `aggregateId`: ID do pedido (Order ID)
- `eventType`: Tipo do evento (OrderCreated, PaymentProcessed, etc.)
- `eventVersion`: Vers√£o do schema (1.0)
- `occurredAt`: Timestamp do evento

---

## üéØ Resumo R√°pido

**T√≥picos a criar:**
1. ‚úÖ `order-created`
2. ‚úÖ `payment-processed`
3. ‚úÖ `saga-completed`
4. ‚úÖ `saga-failed`

**Configura√ß√£o m√≠nima:**
- Parti√ß√µes: 3
- Replica√ß√£o: 1 (dev) / 3 (prod)
- Retention: 7 dias (dev) / 30 dias (prod)

**Ap√≥s criar os t√≥picos:**
- Informe o endere√ßo do Kafka: `KAFKA_BOOTSTRAP_SERVERS=<endere√ßo>:9092`
- A aplica√ß√£o se conectar√° automaticamente quando `MESSAGE_BROKER_TYPE=KAFKA`

---

## üß™ Teste r√°pido de publica√ß√£o/consumo

1) Suba a aplica√ß√£o com Kafka:
```bash
export MESSAGE_BROKER_TYPE=KAFKA
export KAFKA_BOOTSTRAP_SERVERS=localhost:9092
mvn spring-boot:run
```

2) Crie um pedido (exemplo):
```bash
curl -X POST http://localhost:8081/api/v1/orders \
  -H "Content-Type: application/json" \
  -d '{
    "customerId":"11111111-1111-1111-1111-111111111111",
    "customerName":"Teste",
    "customerEmail":"teste@example.com",
    "paymentMethod":"CREDIT_CARD",
    "currency":"BRL",
    "items":[{"productId":"22222222-2222-2222-2222-222222222222","productName":"Item","quantity":1,"unitPrice":100.0}]
  }'
```

3) Consuma eventos publicados:
```bash
kafka-console-consumer --bootstrap-server localhost:9092 --topic order-created --from-beginning
```

4) T√≥picos gerados automaticamente (KafkaAdmin):
- order-created
- payment-processed
- saga-completed
- saga-failed

5) Onde os t√≥picos s√£o criados no c√≥digo:
- `KafkaConfiguration` (`backend/src/main/java/com/marcelo/orchestrator/infrastructure/messaging/config/KafkaConfiguration.java`)
  - Beans `NewTopic` (order-created, payment-processed, saga-completed, saga-failed)
  - `KafkaAdmin` usa `spring.kafka.bootstrap-servers`

6) Publica√ß√£o (Adapter):
- `KafkaEventPublisherAdapter` (`backend/src/main/java/com/marcelo/orchestrator/infrastructure/messaging/adapter/KafkaEventPublisherAdapter.java`)
  - Mapeia eventType ‚Üí t√≥pico
  - Headers: eventId, aggregateId, eventType, eventVersion, occurredAt

---

## üåê UI do Kafka (Observabilidade)

- A UI do Kafka roda em:
  - `http://localhost:8080/ui/clusters/Local-Apache/brokers`
- Permite:
  - Visualizar brokers, t√≥picos, consumer groups e mensagens
  - Navegar at√©:
    - **Clusters ‚Üí Local-Apache ‚Üí Topics** para ver `order-created`, `payment-processed`, `saga-completed`, `saga-failed`
    - **Consumer Groups** para monitorar consumo

Use essa UI como painel principal para validar:
- Se os t√≥picos foram criados
- Se as mensagens est√£o sendo publicadas corretamente pelos testes end-to-end

**üìÖ Documento criado em:** 12/12/2025  
**üë®‚Äçüíª Mantido por:** Marcelo Hernandes da Silva

